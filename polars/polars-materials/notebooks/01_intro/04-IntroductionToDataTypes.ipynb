{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d910ee57-0819-40f3-b345-0deece619afa",
   "metadata": {},
   "source": [
    "## What is a Polars `DataFrame`?\n",
    "In this lecture we have a high-level look at a Polars `DataFrame` and learn:\n",
    "- how to access important metadata\n",
    "- how to compare schema\n",
    "- how Polars stores data with Apache Arrow\n",
    "- what happens when we modify a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350b0f1-ff14-4097-94a2-a4f937b89fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a4ca2-4a74-41c0-8640-501a2f16a6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_file = \"../data/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1b14e-6642-43ec-8185-2e0924d8ca85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.read_csv(csv_file)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dfc421-2bde-42d7-b3d2-64ec4a20a291",
   "metadata": {},
   "source": [
    "A Polars `DataFrame`:\n",
    "- is a tabular dataset stored in an Arrow Table (see below)\n",
    "- has a height and a width\n",
    "- has unique string column names\n",
    "- has a data type for each column\n",
    "- has methods for transforming the data stored in the Arrow Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151d339-2df2-4669-8522-99339d06ce56",
   "metadata": {},
   "source": [
    "We can get the height (number of rows) and width (number of columns) as attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66a40c-1a5d-4ec9-b60b-9c076c932102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89fd9b5-a49f-49e4-9cec-20cce7f1f96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ff417-4da4-4121-bc46-a80835f423bc",
   "metadata": {},
   "source": [
    "## Data type schema\n",
    "\n",
    "Every column in a `DataFrame` has a data type called a `dtype`.\n",
    "\n",
    "We can get a `pl.Schema` that maps column names to dtypes with the `.schema` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d8400-a4cb-4020-85d4-9ed663e99d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b552a-09c3-4cc7-9699-ae7099bb0c46",
   "metadata": {},
   "source": [
    "The `schema` has a Polars type `pl.Schema`. We can also create a `pl.Schema` manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f607db-ecb6-40f0-91fa-f970d0d6befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Schema(\n",
    "    [\n",
    "        (\"a\", pl.Int64), \n",
    "        (\"b\", pl.Float64)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fb711-9ccb-47d2-b831-b5f4d470e28c",
   "metadata": {},
   "source": [
    "When testing data pipelines a common task is to compare the output `schema` with an expected schema. While we can do a quick comparison with `==` a more important point for effective debugging is to explain what any differences are if there are differences. \n",
    "\n",
    "Below we define a function that can do this comparison and report on the differences. Note that there is nothing Polars-specific about this code, it uses Python methods throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495fce8-7bf8-4624-9740-466c4b8f08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_polars_schema(\n",
    "        df_schema:pl.Schema, \n",
    "        target_schema: pl.Schema\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare two pl.Schema and report on any differences\n",
    "    Args:\n",
    "        df_schema (OrderedDict): The schema of our DataFrame\n",
    "        target_schema (OrderedDict): The target schema of our DataFrame that we are comparing to\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing comparison details, with keys indicating the type of difference\n",
    "    \"\"\"\n",
    "    # Check if they are the same\n",
    "    if df_schema == target_schema:\n",
    "        return {\"match\": True}\n",
    "    \n",
    "    # Otherwise do a detailed comparison\n",
    "    comparison_result = {\n",
    "        \"match\": False,\n",
    "        \"differences\": {}\n",
    "    }\n",
    "    \n",
    "    # Check keys\n",
    "    df_keys = set(df_schema.keys())\n",
    "    target_keys = set(target_schema.keys())\n",
    "    \n",
    "    # Check for missing or extra keys\n",
    "    missing_in_target_schema = df_keys - target_keys\n",
    "    missing_in_df_schema = target_keys - df_keys\n",
    "    \n",
    "    if missing_in_target_schema:\n",
    "        comparison_result[\"differences\"][\"keys_missing_in_target\"] = list(missing_in_target_schema)\n",
    "    \n",
    "    if missing_in_df_schema:\n",
    "        comparison_result[\"differences\"][\"keys_missing_in_df\"] = list(missing_in_df_schema)\n",
    "    \n",
    "    # Check common keys for dtype differences\n",
    "    common_keys = df_keys.intersection(target_keys)\n",
    "    \n",
    "    dtype_differences = {}\n",
    "    for key in common_keys:\n",
    "        if df_schema[key] != target_schema[key]:\n",
    "            dtype_differences[key] = {\n",
    "                \"df_type\": str(df_schema[key]),\n",
    "                \"target_type\": str(target_schema[key])\n",
    "            }\n",
    "    \n",
    "    if dtype_differences:\n",
    "        comparison_result[\"differences\"][\"dtype_mismatches\"] = dtype_differences\n",
    "    \n",
    "    return comparison_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4de138-b78e-4755-aa2c-cca97fd8e560",
   "metadata": {},
   "source": [
    "We now do an example to see what the output looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac8b4a-943e-4901-aba5-20494d7c1c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def schema_comparison_example():\n",
    "    # Create a sample DataFrame\n",
    "    df = pl.DataFrame(\n",
    "        {\n",
    "            \"col1\":[0,1],\n",
    "            \"col2\":[0.0,1.0],\n",
    "            \"col3\":[\"0\",\"1\"],\n",
    "        }\n",
    "    )\n",
    "    df_schema = df.schema\n",
    "    # Create a target with a mismatched schema compared to df\n",
    "    target_schema = pl.Schema([\n",
    "        (\"col1\", pl.Int64),\n",
    "        (\"col2\", pl.Float32),\n",
    "        (\"col4\", pl.Date),\n",
    "    ])\n",
    "    \n",
    "    # Compare the schema\n",
    "    comparison = compare_polars_schema(df_schema=df.schema, target_schema=target_schema)\n",
    "    print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e628f-7915-46f6-ac61-879028cf13b3",
   "metadata": {},
   "source": [
    "And then we run the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e132077-5f9a-4723-9947-18002f16f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_comparison_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9d084-18b7-4604-8628-35a73fa57a18",
   "metadata": {},
   "source": [
    "In an actual testing suite we would of course raise an `Exception` if the schema didn't match the target rather than just printing the output.\n",
    "\n",
    "As well as `schema` there is also a `dtypes` attribute (as in Pandas). However, this gives a `list` of dtypes with no column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723eaef-e948-410d-b108-c3ae9acc9ea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd4917-18e1-472f-a943-9ca369047d32",
   "metadata": {},
   "source": [
    "A `Series` also has a data type attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e16ff-e27b-485f-a978-641dbb846f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Name'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0988c35-d159-45de-9d83-984bf8ab0733",
   "metadata": {},
   "source": [
    "### Supertypes\n",
    "We can group the dtypes into groups:\n",
    "- integers e.g. pl.Int8,pl.Int16 etc\n",
    "- floats pl.Float32,pl.Float64\n",
    "- string pl.String\n",
    "- boolean pl.Boolean\n",
    "- datetime pl.Datetime,pl.Date etc\n",
    "\n",
    "Polars also has a concept of supertypes. Supertypes occur where we are trying to do an operation involving columns that have different types. If the dtypes of these columns have a supertype all columns are cast to that type to do the operation. \n",
    "\n",
    "Supertypes are defined on a given pair of dtypes rather than being universal. Here are some simple examples:\n",
    "- pl.Int8 & pl.Int16 -> pl.Int16\n",
    "- pl.Float32 & pl.Float64 -> pl.Float64\n",
    "\n",
    "There are also rules in place for other combinations e.g.:\n",
    "- pl.Int64 & pl.Boolean -> pl.Boolean\n",
    "- pl.Int32 & pl.Float32 -> pl.Float64 (following a convention set by Numpy)\n",
    "- any dtype & pl.String -> pl.String (any column can be cast to string)\n",
    "\n",
    "We see an example of a supertype in the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54ff62-ebcf-4773-aaab-7899378b63cf",
   "metadata": {},
   "source": [
    "## Apache Arrow\n",
    "\n",
    "A classic Pandas `DataFrame` stores its data in Numpy arrays. In Polars the data is stored in an Arrow Table. \n",
    "\n",
    "> I refer to *classic* Pandas meaning basically pre-version 2.0 of Pandas that was the dominant `DataFrame` for more than a decade. These days the different versions of Pandas differ so much that it becomes challenging to make comparisons of what you can do in each, especially for someone like me who has barely used Pandas in recent years.\n",
    "\n",
    "We can see this Arrow Table by calling `to_arrow` - this is a cheap operation as it is just viewing the underlying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512cf66-861b-49cc-b5b2-e14876b3a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_arrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb223ed-509e-4723-9158-8f40ca9975c3",
   "metadata": {},
   "source": [
    "An Arrow Table is a collection of Arrow Arrays - these are one-dimensional vectors that are the fundamental data store. We can see the Arrow Array for a column by calling `to_arrow` on a `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39e53b-e698-4408-b003-b8670e0494df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].to_arrow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287c0c3-be08-498b-bb77-41752a9bae18",
   "metadata": {},
   "source": [
    "### What is Apache Arrow?\n",
    "Apache Arrow is an open source cross-language project to store tabular data in-memory. Apache Arrow is both:\n",
    "- a specificiation for how data should be represented in memory\n",
    "- a set of libraries in different languages that implement that specification\n",
    "\n",
    "\n",
    "### Why does `Polars` use `Apache Arrow`?\n",
    "The Apache Arrow project developed when it became clear that Numpy arrays - designed for scientific computing - are not the optimal data store for tabular data.\n",
    "\n",
    "Arrow allows for:\n",
    "- a standardised way of representing data across packages and languages\n",
    "- sharing data without copying between processes (known as \"zero-copy\")\n",
    "- faster vectorised calculations\n",
    "- working with larger-than-memory data in chunks\n",
    "- consistent representation of missing data\n",
    "- built-in support for string data\n",
    "- built-in support for nested data\n",
    "\n",
    "Overall, Polars can process data more quickly and with less memory usage because of Arrow.\n",
    "\n",
    "### What are the downsides of `Apache Arrow`?\n",
    "The design of Arrow is optimised for operations on one-dimensional columns, whreas the design of Numpy is optimised for operations on multi-dimensional arrays. This tradeoff means some kinds of operations will be slower with Arrow data compared to Numpy:\n",
    "- transposing a dataframe\n",
    "- doing matrix multiplication/linear algebra on a `dataframe`\n",
    "\n",
    "For this kind of use case - where calculations require accessing data by row and column - it may be faster to convert to a Numpy array.\n",
    "\n",
    "### So what is the relationship between a Polars `DataFrame` and Arrow data?\n",
    "A Polars `DataFrame` holds references to an Arrow Table which holds references to Arrow Arrays. We can think of a Polars `DataFrame` being a lightweight object that points to the lightweight Arrow Table which points to the heavyweight Arrow Arrays (heavyweight because they hold the actual data). \n",
    "\n",
    "This detached structure means we can make changes to the cheap `DataFrame` wrapper and copy none (or a minimal amount) of the data in the Arrow Arrays. \n",
    "\n",
    "We now do some examples of how we can do quick operations because they don't change the data. For this we create a large `DataFrame` with random values (note how we can populate a `DataFrame` directly from a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c9314-7b5a-4229-a139-2bc51726abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shape = (1_000_000,100)\n",
    "df_polars = pl.DataFrame(\n",
    "    np.random.standard_normal(df_shape)\n",
    ")\n",
    "df_polars.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6791c74-a83d-4646-89a9-9ee12bfb79d6",
   "metadata": {},
   "source": [
    "And we confirm the `DataFrame` is the correct shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dd959-f7db-4489-a533-873375dbf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329da875-91a8-41ca-a444-0579739e41a2",
   "metadata": {},
   "source": [
    "### Dropping a column\n",
    "We see how long it takes to drop a column from a Polars `DataFrame`. \n",
    "\n",
    "> We use the IPython `timeit` module to time performance in a cell. By default `timeit` runs the target code many times to get statistics of how long it takes. The default number of iterations tend to be more than necessary. We can control the number of iterations with the -n and -r arguments. The total number of iterations is then n*r. Here we do 1*3 = 3 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039c1f3-98e0-4721-9556-0a6a5c1248c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "df_polars.drop(\"column_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc1b9f5-2f12-4869-a476-e418fcf65e89",
   "metadata": {},
   "source": [
    "> You may get a warning about some runs being much faster than others. Generally it's best to just run a few times until you get a run with consistent timings so the warning disappears. \n",
    "\n",
    "Polars does this `drop` very fast (and much faster than Pandas). This is because Polars just creates a new `DataFrame` object (a cheap operation) that points to all the Arrow Arrays except `column_0`. Polars basically just loops through the list of column names for this operation!\n",
    "\n",
    "### Renaming a column\n",
    "We have a similar fast performance whenever we change some part of a `DataFrame` that does not affect the actual data in the columns. For example, if we rename a column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4fc38-3a4d-4fe0-854d-98bb8474c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "df_polars.rename({\"column_0\":\"a\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb10f0-9b99-4ada-9339-6d143b0a79aa",
   "metadata": {},
   "source": [
    "Polars again does this very fast because it just updates the column name and checks the column names are still unique.\n",
    "\n",
    "### Cloning a `DataFrame`\n",
    "Or if we create a new `DataFrame` by cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5b73f-9e65-4d5b-98ea-3af13778f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r3\n",
    "df_polars.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c09d0d-dbc1-4f47-8d73-32f648e7bd79",
   "metadata": {},
   "source": [
    "In this case Polars has created a new `DataFrame` object that points at the same Arrow Table.\n",
    "### Updating a cloned `DataFrame`\n",
    "\n",
    "Although the new and old `DataFrames` initially point at the same Arrow Table we do not need to worry about changes to one affecting the other.\n",
    "\n",
    "If we make changes to a value in one of the `DataFrames` - say the new `DataFrame` - then the new `DataFrame` will:\n",
    "- copy the data in **the column that has changed** to a new Arrow Array\n",
    "- create a new Arrow Table that points to the updated Arrow Array along with the unchanged Arrow Arrays\n",
    "\n",
    "So now we have:\n",
    "- two `DataFrames` that point to:\n",
    "- two Arrow Tables that point to:\n",
    "- the same Array Arrays for the unchanged columns and different Arrow Arrays for the changed column\n",
    "\n",
    "In this way we create a new `DataFrame` but **only ever have to copy data in columns that change**. We see how changes to the new `DataFrame` do not affect the old `DataFrame` in this example where we change the first value in the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ed8f1-f0df-4f73-b404-663d52296066",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars2 = df_polars.clone()\n",
    "df_polars2[0,0] = 1000\n",
    "df_polars2[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81803749-c609-4d2e-aaa9-547da34aa04d",
   "metadata": {},
   "source": [
    "In the original `DataFrame` we still have the original value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a6ef9-6b94-4289-af6d-cd7930b48c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3ba51-b738-4c99-9186-39b5104e9f30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Exercises\n",
    "In the exercises you will develop your understanding of:\n",
    "- getting the dtypes of a `DataFrame`\n",
    "- getting the dtypes of a `Series`\n",
    "\n",
    "### Exercise 1 \n",
    "\n",
    "What are the dtypes of this `DataFrame`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62401a6d-8351-4c4e-930b-84502c7945f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        'a':[0,1,2],\n",
    "        'b':[0,1,2.0]\n",
    "    },\n",
    "    strict=False\n",
    ")\n",
    "# df<blank>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce3abc-9a1e-4d3c-8a3d-73bc05f6fe86",
   "metadata": {},
   "source": [
    "Note the `strict=True` argument here: this tells Polars that if the types in one of the columns are not homogenous then it should use the supertype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5fe6e-d4bc-4e81-81e3-a520ed4ecfc6",
   "metadata": {},
   "source": [
    "Create an expected schema where `a` is `pl.Int64` and `b` is `pl.Int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ece37-2433-46cc-8cbc-33881b8c14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_schema = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b599595e-4cab-48ee-aa79-0238c8685f6e",
   "metadata": {},
   "source": [
    "Compare the actual and expected schemas to find any differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504bf18-7edd-40a9-bc0a-05351411513b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cfb86a5-9c0c-4aae-b4a3-ebb029dcb684",
   "metadata": {},
   "source": [
    "Correct the schema and check the comparison again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fff25-a565-45a3-a53d-dd26df0ff98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeb8821a-8e1a-4686-aed1-229329c515f7",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "### Solution to Exercise 1\n",
    "What are the dtypes of this `DataFrame`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53002fb-546b-407c-9551-fe7c73a5cdf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {'a':[0,1,2],'b':[0,1,2.0]},\n",
    "    strict=False\n",
    ")\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1041b0-3236-4545-b9cb-ba012ca04a59",
   "metadata": {},
   "source": [
    "Create an expected dtype where `a` is `pl.Int64` and `b` is `pl.Int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156b359-a4f4-451f-83be-7a69383e78c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "target_schema = pl.Schema([(\"a\", pl.Int64), (\"b\", pl.Int64)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c703ba-069c-40a3-9272-7b513cde8816",
   "metadata": {},
   "source": [
    "Compare the actual and expected schemas to find any differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038e308-d30f-4397-9247-3989543a9c2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "compare_polars_schema(\n",
    "    df_schema=df.schema,\n",
    "    target_schema=target_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b4e71-ee04-4c30-b016-4fd4afb78ec0",
   "metadata": {},
   "source": [
    "Correct the schema and check the comparison again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bf34e-c5e7-425a-83dc-91123ca592fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "target_schema = pl.Schema([(\"a\", pl.Int64), (\"b\", pl.Float64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607042c-9f8d-42c7-8138-728e5a47dd52",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "compare_polars_schema(\n",
    "    df_schema=df.schema,\n",
    "    target_schema=target_schema\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
